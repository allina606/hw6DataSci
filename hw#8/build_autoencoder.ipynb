{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000001', '00000010', '00000100', '00001000', '00010000', '00100000', '01000000', '10000000']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.identity(8)\n",
    "\n",
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed as array input\n",
    "\n",
    "train_set = np.array(i[:6], dtype='int')\n",
    "test_set = np.array(i[6:], dtype='int')\n",
    "\n",
    "train_set = torch.FloatTensor(train_set)\n",
    "\n",
    "train_set\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode into another vector, lower dimension\n",
    "# uses sigmoid activation function\n",
    "# w - weight, input and b (bias)\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "#     what does self, ?\n",
    "    def __init__(self, ):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "#         what does 20 do, change to 10 and 5?\n",
    "        self.f1 = nn.Linear(len(i),20)\n",
    "        self.f2 = nn.Linear(20, 10)\n",
    "        self.f3 = nn.Linear(10, 20)\n",
    "        self.f4 = nn.Linear(20,len(i))\n",
    "        self.activate = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, a):\n",
    "        a = self.activate(self.f1(a))\n",
    "        a = self.activate(self.f2(a))\n",
    "        a = self.activate(self.f3(a))\n",
    "        a = self.f4(a)\n",
    "        return a\n",
    "    \n",
    "autoenc = AutoEncoder()\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(autoenc.parameters(), lr = 0.01, weight_decay = 0.5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss:  0.3617823581691125\n",
      "epoch:  2  loss:  0.4295094789694424\n",
      "epoch:  3  loss:  0.1909656646653571\n",
      "epoch:  4  loss:  0.12673505720530046\n",
      "epoch:  5  loss:  0.027959966215435558\n",
      "epoch:  6  loss:  0.04114147774391674\n",
      "epoch:  7  loss:  0.012987368628603396\n",
      "epoch:  8  loss:  0.005988045100069321\n",
      "epoch:  9  loss:  0.005864319476732282\n",
      "epoch:  10  loss:  0.0029145950525111017\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "def predict(set_to_get, training=False):\n",
    "    t_loss = 0\n",
    "    s = 0\n",
    "    for a in range(len(set_to_get)):\n",
    "        input = Variable(train_set[a]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0)>0:\n",
    "            output = autoenc(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criteria(output, target)\n",
    "            mean_corrector = i/float(torch.sum(target.data>0)+1e-10)\n",
    "            loss.backward()\n",
    "            t_loss += np.sqrt(float(loss.data)*mean_corrector)\n",
    "            s += 1\n",
    "            if training: optimizer.step()\n",
    "    return t_loss, s\n",
    "\n",
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    loss = predict(train_set,True)\n",
    "            \n",
    "    print('epoch: ', str(epoch), ' loss: ', str((loss[0]/loss[1])[0][0]))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss =  0.003360726490098086\n"
     ]
    }
   ],
   "source": [
    "test_loss = predict(test_set)\n",
    "print(\"test_loss = \", str((test_loss[0]/test_loss[1])[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
