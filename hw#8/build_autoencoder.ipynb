{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "i = np.identity(8)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed as array input\n",
    "\n",
    "train_set = np.array(i[:6], dtype='int')\n",
    "test_set = np.array(i[6:], dtype='int')\n",
    "\n",
    "train_set = torch.FloatTensor(train_set)\n",
    "\n",
    "train_set\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.f1 = nn.Linear(len(i),20)\n",
    "        self.f2 = nn.Linear(20, 10)\n",
    "        self.f3 = nn.Linear(10, 20)\n",
    "        self.f4 = nn.Linear(20,len(i))\n",
    "        self.activate = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, a):\n",
    "        a = self.activate(self.f1(a))\n",
    "        a = self.activate(self.f2(a))\n",
    "        a = self.activate(self.f3(a))\n",
    "        a = self.f4(a)\n",
    "        return a\n",
    "    \n",
    "autoenc = AutoEncoder()\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(autoenc.parameters(), lr = 0.01, weight_decay = 0.5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss:  0.3169954120117667\n",
      "epoch:  2  loss:  0.39725646013304505\n",
      "epoch:  3  loss:  0.27318762508562106\n",
      "epoch:  4  loss:  0.12092855568550614\n",
      "epoch:  5  loss:  0.05089509423489281\n",
      "epoch:  6  loss:  0.04409844761405785\n",
      "epoch:  7  loss:  0.007506395797981453\n",
      "epoch:  8  loss:  0.011465298480501518\n",
      "epoch:  9  loss:  0.0031521803629010144\n",
      "epoch:  10  loss:  0.0027645382343591644\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "def predict(set_to_get, training=False):\n",
    "    t_loss = 0\n",
    "    s = 0\n",
    "    for a in range(len(set_to_get)):\n",
    "        input = Variable(train_set[a]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0)>0:\n",
    "            output = autoenc(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criteria(output, target)\n",
    "            mean_corrector = i/float(torch.sum(target.data>0)+1e-10)\n",
    "            loss.backward()\n",
    "            t_loss += np.sqrt(float(loss.data)*mean_corrector)\n",
    "            s += 1\n",
    "            if training: optimizer.step()\n",
    "    return t_loss, s\n",
    "\n",
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    loss = predict(train_set,True)\n",
    "            \n",
    "    print('epoch: ', str(epoch), ' loss: ', str((loss[0]/loss[1])[0][0]))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss =  0.0012117851183737806\n"
     ]
    }
   ],
   "source": [
    "test_loss = predict(test_set)\n",
    "print(\"test_loss = \", str((test_loss[0]/test_loss[1])[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
